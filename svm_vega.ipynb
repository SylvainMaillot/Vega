{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# import the necessary packages\n",
    "import numpy as np\n",
    "import imutils\n",
    "import cv2\n",
    "import os\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import train_test_split\n",
    "from imutils import paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Functions\n",
    "def image_to_feature_vector(image, size=(32, 32)):\n",
    "\t# resize the image to a fixed size, then flatten the image into\n",
    "\t# a list of raw pixel intensities\n",
    "\treturn cv2.resize(image, size).flatten()\n",
    "\n",
    "def extract_color_histogram(image, bins=(8, 8, 8)):\n",
    "\t# extract a 3D color histogram from the HSV color space using\n",
    "\t# the supplied number of `bins` per channel\n",
    "\thsv = cv2.cvtColor(image, cv2.COLOR_BGR2HSV)\n",
    "\thist = cv2.calcHist([hsv], [0, 1, 2], None, bins,\n",
    "\t\t[0, 180, 0, 256, 0, 256])\n",
    "\t# handle normalizing the histogram if we are using OpenCV 2.4.X\n",
    "\tif imutils.is_cv2():\n",
    "\t\thist = cv2.normalize(hist)\n",
    "\t# otherwise, perform \"in place\" normalization in OpenCV 3\n",
    "\telse:\n",
    "\t\tcv2.normalize(hist, hist)\n",
    "\t# return the flattened histogram as the feature vector\n",
    "\treturn hist.flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] describing images...\n",
      "['./train_vega\\\\Ankh.01.jpg', './train_vega\\\\Ankh.02.jpg', './train_vega\\\\Ankh.03.jpg', './train_vega\\\\Ankh.04.jpg', './train_vega\\\\Ankh.05.jpg', './train_vega\\\\Ankh.06.jpg', './train_vega\\\\Ankh.07.jpg', './train_vega\\\\Ankh.08.jpg', './train_vega\\\\Ankh.09.jpg', './train_vega\\\\Ankh.10.jpg', './train_vega\\\\Ankh.11.jpg', './train_vega\\\\Ankh.12.jpg', './train_vega\\\\Ankh.13.jpg', './train_vega\\\\Ankh.14.jpg', './train_vega\\\\Ankh.15.jpg', './train_vega\\\\Ankh.16.jpg', './train_vega\\\\Ankh.17.jpg', './train_vega\\\\Ankh.18.jpg', './train_vega\\\\Ankh.19.jpg', './train_vega\\\\Ankh.20.jpg', './train_vega\\\\Ankh.21.jpg', './train_vega\\\\bouche.01.jpg', './train_vega\\\\bouche.02.jpg', './train_vega\\\\bouche.03.jpg', './train_vega\\\\bouche.04.jpg', './train_vega\\\\bouche.05.jpg', './train_vega\\\\bouche.06.jpg', './train_vega\\\\bouche.07.jpg', './train_vega\\\\bouche.08.jpg', './train_vega\\\\bouche.09.jpg', './train_vega\\\\bouche.10.jpg', './train_vega\\\\bouche.11.jpg', './train_vega\\\\bouche.13.jpg', './train_vega\\\\hibou.1.jpg', './train_vega\\\\hibou.10.jpg', './train_vega\\\\hibou.11.jpg', './train_vega\\\\hibou.12.jpg', './train_vega\\\\hibou.13.jpg', './train_vega\\\\hibou.14.jpg', './train_vega\\\\hibou.15.jpg', './train_vega\\\\hibou.16.jpg', './train_vega\\\\hibou.2.jpg', './train_vega\\\\hibou.3.jpg', './train_vega\\\\hibou.4.jpg', './train_vega\\\\hibou.5.jpg', './train_vega\\\\hibou.6.jpg', './train_vega\\\\hibou.7.jpg', './train_vega\\\\hibou.8.jpg', './train_vega\\\\hibou.9.jpg', './train_vega\\\\lapin.01.jpg', './train_vega\\\\lapin.02.jpg', './train_vega\\\\lapin.03.jpg', './train_vega\\\\lapin.04.jpg', './train_vega\\\\lapin.05.jpg', './train_vega\\\\oeil.01.jpg', './train_vega\\\\oeil.02.jpg', './train_vega\\\\oeil.04.jpg', './train_vega\\\\oeil.07.jpg', './train_vega\\\\oeil.10.jpg', './train_vega\\\\oeil.11.jpg', './train_vega\\\\oeil.12.jpg', './train_vega\\\\oeil.14.jpg', './train_vega\\\\oeil.15.jpg', './train_vega\\\\oeil.20.jpg', './train_vega\\\\oeil.23.jpg', './train_vega\\\\Plume.01.jpg', './train_vega\\\\Plume.02.jpg', './train_vega\\\\Plume.03.jpg', './train_vega\\\\Plume.04.jpg', './train_vega\\\\Plume.05.jpg', './train_vega\\\\Plume.06.jpg', './train_vega\\\\Plume.07.jpg', './train_vega\\\\Plume.08.jpg', './train_vega\\\\Plume.09.jpg', './train_vega\\\\Plume.10.jpg', './train_vega\\\\Plume.11.jpg', './train_vega\\\\Plume.12.jpg', './train_vega\\\\Plume.13.jpg', './train_vega\\\\Plume.14.jpg', './train_vega\\\\Plume.15.jpg', './train_vega\\\\Plume.16.jpg', './train_vega\\\\Plume.17.jpg', './train_vega\\\\Plume.18.jpg', './train_vega\\\\Plume.19.jpg', './train_vega\\\\Plume.20.jpg', './train_vega\\\\Plume.21.jpg', './train_vega\\\\Plume.22.jpg', './train_vega\\\\Plume.23.jpg', './train_vega\\\\Plume.24.jpg', './train_vega\\\\Plume.25.jpg', './train_vega\\\\Plume.26.jpg', './train_vega\\\\Plume.27.jpg', './train_vega\\\\skara.01.jpg', './train_vega\\\\skara.02.jpg', './train_vega\\\\skara.03.jpg', './train_vega\\\\skara.04.jpg', './train_vega\\\\skara.05.jpg', './train_vega\\\\skara.06.jpg', './train_vega\\\\skara.07.jpg', './train_vega\\\\skara.08.jpg', './train_vega\\\\skara.09.jpg', './train_vega\\\\skara.10.jpg', './train_vega\\\\skara.11.jpg', './train_vega\\\\skara.12.jpg', './train_vega\\\\skara.13.jpg', './train_vega\\\\skara.14.jpg', './train_vega\\\\skara.15.jpg', './train_vega\\\\skara.16.jpg', './train_vega\\\\skara.17.jpg', './train_vega\\\\skara.18.jpg', './train_vega\\\\skara.19.jpg', './train_vega\\\\skara.20.jpg']\n"
     ]
    }
   ],
   "source": [
    "#Images\n",
    "# grab the list of images that we'll be describing\n",
    "print(\"[INFO] describing images...\")\n",
    "imagePaths = list(paths.list_images(\"./train_vega\"))\n",
    "print (imagePaths)\n",
    "# initialize the raw pixel intensities matrix, the features matrix,\n",
    "# and labels list\n",
    "rawImages = []\n",
    "features = []\n",
    "labels = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "Singleton array array('skara', \n      dtype='<U5') cannot be considered a valid collection.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-6-ad166a51072f>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     34\u001b[0m \u001b[1;31m# of the data for training and the remaining 25% for testing\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     35\u001b[0m (trainRI, testRI, trainRL, testRL) = train_test_split(\n\u001b[1;32m---> 36\u001b[1;33m \trawImages, labels, test_size=0.25, random_state=42)\n\u001b[0m\u001b[0;32m     37\u001b[0m (trainFeat, testFeat, trainLabels, testLabels) = train_test_split(\n\u001b[0;32m     38\u001b[0m \tfeatures, labels, test_size=0.25, random_state=42)\n",
      "\u001b[1;32mC:\\Users\\Sarah\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_split.py\u001b[0m in \u001b[0;36mtrain_test_split\u001b[1;34m(*arrays, **options)\u001b[0m\n\u001b[0;32m   1687\u001b[0m         \u001b[0mtest_size\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m0.25\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1688\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1689\u001b[1;33m     \u001b[0marrays\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mindexable\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0marrays\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1690\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1691\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mstratify\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\Sarah\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36mindexable\u001b[1;34m(*iterables)\u001b[0m\n\u001b[0;32m    204\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    205\u001b[0m             \u001b[0mresult\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 206\u001b[1;33m     \u001b[0mcheck_consistent_length\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mresult\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    207\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    208\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\Sarah\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36mcheck_consistent_length\u001b[1;34m(*arrays)\u001b[0m\n\u001b[0;32m    175\u001b[0m     \"\"\"\n\u001b[0;32m    176\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 177\u001b[1;33m     \u001b[0mlengths\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0m_num_samples\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mX\u001b[0m \u001b[1;32min\u001b[0m \u001b[0marrays\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mX\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    178\u001b[0m     \u001b[0muniques\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0munique\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlengths\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    179\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0muniques\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\Sarah\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    175\u001b[0m     \"\"\"\n\u001b[0;32m    176\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 177\u001b[1;33m     \u001b[0mlengths\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0m_num_samples\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mX\u001b[0m \u001b[1;32min\u001b[0m \u001b[0marrays\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mX\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    178\u001b[0m     \u001b[0muniques\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0munique\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlengths\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    179\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0muniques\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\Sarah\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36m_num_samples\u001b[1;34m(x)\u001b[0m\n\u001b[0;32m    124\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    125\u001b[0m             raise TypeError(\"Singleton array %r cannot be considered\"\n\u001b[1;32m--> 126\u001b[1;33m                             \" a valid collection.\" % x)\n\u001b[0m\u001b[0;32m    127\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    128\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: Singleton array array('skara', \n      dtype='<U5') cannot be considered a valid collection."
     ]
    }
   ],
   "source": [
    "# loop over the input images\n",
    "for (i, imagePath) in enumerate(imagePaths):\n",
    "\t# load the image and extract the class label (assuming that our\n",
    "\t# path as the format: /path/to/dataset/{class}.{image_num}.jpg\n",
    "\timage = cv2.imread(imagePath)\n",
    "\timage_flip = cv2.flip(image,1)\n",
    "\tlabel = imagePath.split(os.path.sep)[-1].split(\".\")[0]\n",
    "    \n",
    "\t# extract raw pixel intensity \"features\", followed by a color\n",
    "\t# histogram to characterize the color distribution of the pixels\n",
    "\t# in the image\n",
    "\tpixels = image_to_feature_vector(image)\n",
    "\tpixels_flip = image_to_feature_vector(image_flip)\n",
    "\thist = extract_color_histogram(image)\n",
    "\thist_flip = extract_color_histogram(image_flip)\n",
    "\n",
    "\t# update the raw images, features, and labels matricies,\n",
    "\t# respectively\n",
    "\trawImages = np.array(pixels)\n",
    "\trawImages = np.array(pixels_flip)\n",
    "\tfeatures = np.array(hist)\n",
    "\tfeatures = np.array(hist_flip)\n",
    "\tlabels = np.array(label)\n",
    "\tlabels = np.array(label)\n",
    "\n",
    "\t# show an update every 1,000 images\n",
    "\tif i > 0 and i % 1000 == 0:\n",
    "\t\tprint(\"[INFO] processed {}/{}\".format(i, len(imagePaths)))\n",
    "      \n",
    "rawImages = np.array(rawImages)\n",
    "features = np.array(features)\n",
    "labels = np.array(labels)\n",
    "# partition the data into training and testing splits, using 75%\n",
    "# of the data for training and the remaining 25% for testing\n",
    "(trainRI, testRI, trainRL, testRL) = train_test_split(\n",
    "\trawImages, labels, test_size=0.25, random_state=42)\n",
    "(trainFeat, testFeat, trainLabels, testLabels) = train_test_split(\n",
    "\tfeatures, labels, test_size=0.25, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] evaluating raw pixel accuracy...\n",
      "[INFO] raw pixel accuracy: 26.79%\n"
     ]
    }
   ],
   "source": [
    "# train and evaluate a SVM classifer on the raw pixel intensities\n",
    "print(\"[INFO] evaluating raw pixel accuracy...\")\n",
    "model =  SVC(kernel='linear', C=1, random_state=0)\n",
    "model.fit(trainRI, trainRL)\n",
    "acc = model.score(testRI, testRL)\n",
    "print(\"[INFO] raw pixel accuracy: {:.2f}%\".format(acc * 100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] evaluating histogram accuracy...\n",
      "[INFO] histogram accuracy: 66.67%\n"
     ]
    }
   ],
   "source": [
    "# train and evaluate a SVM classifer on the histogram\n",
    "# representations\n",
    "print(\"[INFO] evaluating histogram accuracy...\")\n",
    "model =  SVC()\n",
    "model.fit(trainFeat, trainLabels)\n",
    "acc = model.score(testFeat, testLabels)\n",
    "print(\"[INFO] histogram accuracy: {:.2f}%\".format(acc * 100))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
